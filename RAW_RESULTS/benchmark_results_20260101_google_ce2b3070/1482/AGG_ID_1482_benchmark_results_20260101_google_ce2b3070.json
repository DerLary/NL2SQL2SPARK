{
    "google_1482": {
        "llm": "google",
        "query_id": 1482,
        "nl_query": "Which of the three segments\u2014SME, LAM and KAM\u2014has the biggest and lowest percentage increases in consumption paid in EUR between 2012 and 2013? Increase or Decrease = consumption for 2013 - consumption for 2012; Percentage of Increase = (Increase or Decrease / consumption for 2013) * 100%; The first 4 strings of the Date values in the yearmonth table can represent year",
        "golden_query": "SELECT CAST((SUM(IF(T1.Segment = 'SME' AND T2.Date LIKE '2013%', T2.Consumption, 0)) - SUM(IF(T1.Segment = 'SME' AND T2.Date LIKE '2012%', T2.Consumption, 0))) AS FLOAT) * 100 / SUM(IF(T1.Segment = 'SME' AND T2.Date LIKE '2012%', T2.Consumption, 0)), CAST(SUM(IF(T1.Segment = 'LAM' AND T2.Date LIKE '2013%', T2.Consumption, 0)) - SUM(IF(T1.Segment = 'LAM' AND T2.Date LIKE '2012%', T2.Consumption, 0)) AS FLOAT) * 100 / SUM(IF(T1.Segment = 'LAM' AND T2.Date LIKE '2012%', T2.Consumption, 0)), CAST(SUM(IF(T1.Segment = 'KAM' AND T2.Date LIKE '2013%', T2.Consumption, 0)) - SUM(IF(T1.Segment = 'KAM' AND T2.Date LIKE '2012%', T2.Consumption, 0)) AS FLOAT) * 100 / SUM(IF(T1.Segment = 'KAM' AND T2.Date LIKE '2012%', T2.Consumption, 0)) FROM customers AS T1 INNER JOIN yearmonth AS T2 ON T1.CustomerID = T2.CustomerID",
        "sparksql_query": [
            "WITH ConsumptionByYear AS (SELECT c.`Segment`, YEAR(t.`Date`) AS `Year`, SUM(t.`Price`) AS `TotalConsumption` FROM `customers` c JOIN `transactions_1k` t ON c.`CustomerID` = t.`CustomerID` WHERE c.`Currency` = 'EUR' AND YEAR(t.`Date`) IN (2012, 2013) GROUP BY c.`Segment`, YEAR(t.`Date`)), SegmentConsumption AS (SELECT `Segment`, SUM(CASE WHEN `Year` = 2012 THEN `TotalConsumption` ELSE 0 END) AS `Consumption2012`, SUM(CASE WHEN `Year` = 2013 THEN `TotalConsumption` ELSE 0 END) AS `Consumption2013` FROM ConsumptionByYear GROUP BY `Segment`) SELECT `Segment`, `Consumption2012`, `Consumption2013`, (`Consumption2013` - `Consumption2012`) AS `IncreaseDecrease`, ( CAST((`Consumption2013` - `Consumption2012`) AS DOUBLE) / NULLIF(`Consumption2013`, 0) ) * 100 AS `PercentageIncrease` FROM SegmentConsumption ORDER BY `PercentageIncrease` DESC;",
            "SELECT\n  `c`.`Segment`,\n  SUM(CASE WHEN SUBSTRING(`y`.`Date`, 1, 4) = '2012' THEN `y`.`Consumption` ELSE 0 END) AS `Consumption_2012`,\n  SUM(CASE WHEN SUBSTRING(`y`.`Date`, 1, 4) = '2013' THEN `y`.`Consumption` ELSE 0 END) AS `Consumption_2013`,\n  (SUM(CASE WHEN SUBSTRING(`y`.`Date`, 1, 4) = '2013' THEN `y`.`Consumption` ELSE 0 END) - SUM(CASE WHEN SUBSTRING(`y`.`Date`, 1, 4) = '2012' THEN `y`.`Consumption` ELSE 0 END)) AS `Increase_Decrease`,\n  (CAST((SUM(CASE WHEN SUBSTRING(`y`.`Date`, 1, 4) = '2013' THEN `y`.`Consumption` ELSE 0 END) - SUM(CASE WHEN SUBSTRING(`y`.`Date`, 1, 4) = '2012' THEN `y`.`Consumption` ELSE 0 END)) AS DOUBLE) / NULLIF(SUM(CASE WHEN SUBSTRING(`y`.`Date`, 1, 4) = '2013' THEN `y`.`Consumption` ELSE 0 END), 0)) * 100 AS `Percentage_Increase`\nFROM `yearmonth` AS `y`\nJOIN `customers` AS `c`\n  ON `y`.`CustomerID` = `c`.`CustomerID`\nWHERE\n  SUBSTRING(`y`.`Date`, 1, 4) IN ('2012', '2013')\nGROUP BY\n  `c`.`Segment`\nORDER BY\n  `Percentage_Increase` DESC;",
            "SELECT c.Segment, YEAR(t.Date) AS Year, SUM(t.Price) AS TotalConsumption FROM transactions_1k AS t JOIN customers AS c ON t.CustomerID = c.CustomerID WHERE c.Currency = 'EUR' AND YEAR(t.Date) IN (2012, 2013) GROUP BY c.Segment, YEAR(t.Date) ORDER BY c.Segment, Year;",
            "SELECT c.Segment, SUBSTRING(y.Date, 1, 4) AS Year, SUM(y.Consumption) AS TotalConsumption FROM customers c JOIN yearmonth y ON c.CustomerID = y.CustomerID WHERE c.Currency = 'EUR' AND SUBSTRING(y.Date, 1, 4) IN ('2012', '2013') GROUP BY c.Segment, SUBSTRING(y.Date, 1, 4) ORDER BY c.Segment, Year",
            "WITH YearlyConsumption AS (SELECT c.Segment, SUBSTR(t.Date, 1, 4) AS Year, SUM(t.Price) AS TotalConsumption FROM customers c JOIN transactions_1k t ON c.CustomerID = t.CustomerID WHERE c.Currency = 'EUR' AND SUBSTR(t.Date, 1, 4) IN ('2012', '2013') GROUP BY c.Segment, SUBSTR(t.Date, 1, 4)) SELECT yc2013.Segment, yc2013.TotalConsumption AS Consumption2013, yc2012.TotalConsumption AS Consumption2012, (yc2013.TotalConsumption - yc2012.TotalConsumption) AS IncreaseDecrease, (CAST((yc2013.TotalConsumption - yc2012.TotalConsumption) AS DOUBLE) / yc2013.TotalConsumption) * 100 AS PercentageIncrease FROM YearlyConsumption yc2013 JOIN YearlyConsumption yc2012 ON yc2013.Segment = yc2012.Segment WHERE yc2013.Year = '2013' AND yc2012.Year = '2012' ORDER BY PercentageIncrease DESC;",
            "SELECT c.Segment, YEAR(t.Date) AS Year, SUM(t.Price) AS TotalConsumption FROM transactions_1k AS t JOIN customers AS c ON t.CustomerID = c.CustomerID WHERE c.Currency = 'EUR' AND YEAR(t.Date) IN (2012, 2013) GROUP BY c.Segment, YEAR(t.Date) ORDER BY c.Segment, Year;",
            "\nSELECT\n  c.`Segment`,\n  SUM(CASE WHEN SUBSTRING(y.`Date`, 1, 4) = '2012' THEN y.`Consumption` ELSE 0 END) AS Consumption_2012,\n  SUM(CASE WHEN SUBSTRING(y.`Date`, 1, 4) = '2013' THEN y.`Consumption` ELSE 0 END) AS Consumption_2013,\n  (SUM(CASE WHEN SUBSTRING(y.`Date`, 1, 4) = '2013' THEN y.`Consumption` ELSE 0 END) - SUM(CASE WHEN SUBSTRING(y.`Date`, 1, 4) = '2012' THEN y.`Consumption` ELSE 0 END)) AS Increase_Decrease,\n  (\n    (CAST(SUM(CASE WHEN SUBSTRING(y.`Date`, 1, 4) = '2013' THEN y.`Consumption` ELSE 0 END) AS DOUBLE) - SUM(CASE WHEN SUBSTRING(y.`Date`, 1, 4) = '2012' THEN y.`Consumption` ELSE 0 END))\n    / NULLIF(CAST(SUM(CASE WHEN SUBSTRING(y.`Date`, 1, 4) = '2013' THEN y.`Consumption` ELSE 0 END) AS DOUBLE), 0)\n  ) * 100 AS Percentage_Increase\nFROM yearmonth AS y\nJOIN customers AS c\n  ON y.`CustomerID` = c.`CustomerID`\nWHERE\n  SUBSTRING(y.`Date`, 1, 4) IN ('2012', '2013')\nGROUP BY\n  c.`Segment`\nORDER BY\n  Percentage_Increase DESC;\n",
            "\nSELECT\n  c.`Segment`,\n  SUM(CASE WHEN SUBSTRING(y.`Date`, 1, 4) = '2012' THEN y.`Consumption` ELSE 0 END) AS Consumption_2012,\n  SUM(CASE WHEN SUBSTRING(y.`Date`, 1, 4) = '2013' THEN y.`Consumption` ELSE 0 END) AS Consumption_2013,\n  (SUM(CASE WHEN SUBSTRING(y.`Date`, 1, 4) = '2013' THEN y.`Consumption` ELSE 0 END) - SUM(CASE WHEN SUBSTRING(y.`Date`, 1, 4) = '2012' THEN y.`Consumption` ELSE 0 END)) AS Increase_Decrease,\n  (\n    (CAST(SUM(CASE WHEN SUBSTRING(y.`Date`, 1, 4) = '2013' THEN y.`Consumption` ELSE 0 END) AS DOUBLE) - SUM(CASE WHEN SUBSTRING(y.`Date`, 1, 4) = '2012' THEN y.`Consumption` ELSE 0 END))\n    / NULLIF(SUM(CASE WHEN SUBSTRING(y.`Date`, 1, 4) = '2012' THEN y.`Consumption` ELSE 0 END), 0)\n  ) * 100 AS Percentage_Increase\nFROM yearmonth AS y\nJOIN customers AS c\n  ON y.`CustomerID` = c.`CustomerID`\nWHERE\n  SUBSTRING(y.`Date`, 1, 4) IN ('2012', '2013')\nGROUP BY\n  c.`Segment`\nORDER BY\n  Percentage_Increase DESC;\n",
            "SELECT c.Segment, YEAR(t.Date) AS Year, SUM(t.Price) AS TotalConsumption FROM transactions_1k AS t JOIN customers AS c ON t.CustomerID = c.CustomerID WHERE c.Currency = 'EUR' AND YEAR(t.Date) IN (2012, 2013) GROUP BY c.Segment, YEAR(t.Date) ORDER BY c.Segment, Year;",
            "SELECT\n  `c`.`Segment`,\n  SUM(CASE WHEN SUBSTRING(`y`.`Date`, 1, 4) = '2012' THEN `y`.`Consumption` ELSE 0 END) AS `Consumption_2012`,\n  SUM(CASE WHEN SUBSTRING(`y`.`Date`, 1, 4) = '2013' THEN `y`.`Consumption` ELSE 0 END) AS `Consumption_2013`,\n  (SUM(CASE WHEN SUBSTRING(`y`.`Date`, 1, 4) = '2013' THEN `y`.`Consumption` ELSE 0 END) - SUM(CASE WHEN SUBSTRING(`y`.`Date`, 1, 4) = '2012' THEN `y`.`Consumption` ELSE 0 END)) AS `Increase_Decrease`,\n  (CAST((SUM(CASE WHEN SUBSTRING(`y`.`Date`, 1, 4) = '2013' THEN `y`.`Consumption` ELSE 0 END) - SUM(CASE WHEN SUBSTRING(`y`.`Date`, 1, 4) = '2012' THEN `y`.`Consumption` ELSE 0 END)) AS DOUBLE) / NULLIF(SUM(CASE WHEN SUBSTRING(`y`.`Date`, 1, 4) = '2013' THEN `y`.`Consumption` ELSE 0 END), 0)) * 100 AS `Percentage_Increase`\nFROM `yearmonth` AS `y`\nJOIN `customers` AS `c`\n  ON `y`.`CustomerID` = `c`.`CustomerID`\nWHERE\n  SUBSTRING(`y`.`Date`, 1, 4) IN ('2012', '2013')\nGROUP BY\n  `c`.`Segment`\nORDER BY\n  `Percentage_Increase` DESC;"
        ],
        "difficulty": "challenging",
        "execution_status": [
            "ERROR",
            "VALID",
            "ERROR",
            "VALID",
            "ERROR",
            "ERROR",
            "VALID",
            "VALID",
            "ERROR",
            "VALID"
        ],
        "query_result": [
            null,
            [
                [
                    "KAM",
                    "135424912.7400001",
                    "1094385521.0699985",
                    "958960608.3299984",
                    "87.62548387814991"
                ],
                [
                    "LAM",
                    "118970734.52000001",
                    "929854390.5599992",
                    "810883656.0399992",
                    "87.20544466662672"
                ],
                [
                    "SME",
                    "152513750.5300001",
                    "984326643.6499959",
                    "831812893.1199958",
                    "84.50577849193824"
                ]
            ],
            null,
            [
                [
                    "KAM",
                    "2012",
                    "646663.61"
                ],
                [
                    "KAM",
                    "2013",
                    "4224041.47"
                ],
                [
                    "LAM",
                    "2012",
                    "676212.68"
                ],
                [
                    "LAM",
                    "2013",
                    "4326606.130000001"
                ],
                [
                    "SME",
                    "2012",
                    "869537.5200000006"
                ],
                [
                    "SME",
                    "2013",
                    "7258151.959999993"
                ]
            ],
            null,
            null,
            [
                [
                    "KAM",
                    "135424912.7400001",
                    "1094385521.0699985",
                    "958960608.3299984",
                    "87.62548387814991"
                ],
                [
                    "LAM",
                    "118970734.52000001",
                    "929854390.5599992",
                    "810883656.0399992",
                    "87.20544466662672"
                ],
                [
                    "SME",
                    "152513750.5300001",
                    "984326643.6499959",
                    "831812893.1199958",
                    "84.50577849193824"
                ]
            ],
            [
                [
                    "KAM",
                    "135424912.7400001",
                    "1094385521.0699985",
                    "958960608.3299984",
                    "708.1124062978648"
                ],
                [
                    "LAM",
                    "118970734.52000001",
                    "929854390.5599992",
                    "810883656.0399992",
                    "681.5824574939332"
                ],
                [
                    "SME",
                    "152513750.5300001",
                    "984326643.6499959",
                    "831812893.1199958",
                    "545.4018999790939"
                ]
            ],
            null,
            [
                [
                    "KAM",
                    "135424912.7400001",
                    "1094385521.0699985",
                    "958960608.3299984",
                    "87.62548387814991"
                ],
                [
                    "LAM",
                    "118970734.52000001",
                    "929854390.5599992",
                    "810883656.0399992",
                    "87.20544466662672"
                ],
                [
                    "SME",
                    "152513750.5300001",
                    "984326643.6499959",
                    "831812893.1199958",
                    "84.50577849193824"
                ]
            ]
        ],
        "ground_truth": [
            [],
            [
                {
                    "((CAST((sum((IF(((Segment = SME) AND Date LIKE 2013%), Consumption, 0))) - sum((IF(((Segment = SME) AND Date LIKE 2012%), Consumption, 0)))) AS FLOAT) * 100) / sum((IF(((Segment = SME) AND Date LIKE 2012%), Consumption, 0))))": 545.4018808857362,
                    "((CAST((sum((IF(((Segment = LAM) AND Date LIKE 2013%), Consumption, 0))) - sum((IF(((Segment = LAM) AND Date LIKE 2012%), Consumption, 0)))) AS FLOAT) * 100) / sum((IF(((Segment = LAM) AND Date LIKE 2012%), Consumption, 0))))": 681.5824507359694,
                    "((CAST((sum((IF(((Segment = KAM) AND Date LIKE 2013%), Consumption, 0))) - sum((IF(((Segment = KAM) AND Date LIKE 2012%), Consumption, 0)))) AS FLOAT) * 100) / sum((IF(((Segment = KAM) AND Date LIKE 2012%), Consumption, 0))))": 708.1124296835188
                }
            ],
            [],
            [
                {
                    "((CAST((sum((IF(((Segment = SME) AND Date LIKE 2013%), Consumption, 0))) - sum((IF(((Segment = SME) AND Date LIKE 2012%), Consumption, 0)))) AS FLOAT) * 100) / sum((IF(((Segment = SME) AND Date LIKE 2012%), Consumption, 0))))": 545.4018808857362,
                    "((CAST((sum((IF(((Segment = LAM) AND Date LIKE 2013%), Consumption, 0))) - sum((IF(((Segment = LAM) AND Date LIKE 2012%), Consumption, 0)))) AS FLOAT) * 100) / sum((IF(((Segment = LAM) AND Date LIKE 2012%), Consumption, 0))))": 681.5824507359694,
                    "((CAST((sum((IF(((Segment = KAM) AND Date LIKE 2013%), Consumption, 0))) - sum((IF(((Segment = KAM) AND Date LIKE 2012%), Consumption, 0)))) AS FLOAT) * 100) / sum((IF(((Segment = KAM) AND Date LIKE 2012%), Consumption, 0))))": 708.1124296835188
                }
            ],
            [],
            [],
            [
                {
                    "((CAST((sum((IF(((Segment = SME) AND Date LIKE 2013%), Consumption, 0))) - sum((IF(((Segment = SME) AND Date LIKE 2012%), Consumption, 0)))) AS FLOAT) * 100) / sum((IF(((Segment = SME) AND Date LIKE 2012%), Consumption, 0))))": 545.4018808857362,
                    "((CAST((sum((IF(((Segment = LAM) AND Date LIKE 2013%), Consumption, 0))) - sum((IF(((Segment = LAM) AND Date LIKE 2012%), Consumption, 0)))) AS FLOAT) * 100) / sum((IF(((Segment = LAM) AND Date LIKE 2012%), Consumption, 0))))": 681.5824507359694,
                    "((CAST((sum((IF(((Segment = KAM) AND Date LIKE 2013%), Consumption, 0))) - sum((IF(((Segment = KAM) AND Date LIKE 2012%), Consumption, 0)))) AS FLOAT) * 100) / sum((IF(((Segment = KAM) AND Date LIKE 2012%), Consumption, 0))))": 708.1124296835188
                }
            ],
            [
                {
                    "((CAST((sum((IF(((Segment = SME) AND Date LIKE 2013%), Consumption, 0))) - sum((IF(((Segment = SME) AND Date LIKE 2012%), Consumption, 0)))) AS FLOAT) * 100) / sum((IF(((Segment = SME) AND Date LIKE 2012%), Consumption, 0))))": 545.4018808857362,
                    "((CAST((sum((IF(((Segment = LAM) AND Date LIKE 2013%), Consumption, 0))) - sum((IF(((Segment = LAM) AND Date LIKE 2012%), Consumption, 0)))) AS FLOAT) * 100) / sum((IF(((Segment = LAM) AND Date LIKE 2012%), Consumption, 0))))": 681.5824507359694,
                    "((CAST((sum((IF(((Segment = KAM) AND Date LIKE 2013%), Consumption, 0))) - sum((IF(((Segment = KAM) AND Date LIKE 2012%), Consumption, 0)))) AS FLOAT) * 100) / sum((IF(((Segment = KAM) AND Date LIKE 2012%), Consumption, 0))))": 708.1124296835188
                }
            ],
            [],
            [
                {
                    "((CAST((sum((IF(((Segment = SME) AND Date LIKE 2013%), Consumption, 0))) - sum((IF(((Segment = SME) AND Date LIKE 2012%), Consumption, 0)))) AS FLOAT) * 100) / sum((IF(((Segment = SME) AND Date LIKE 2012%), Consumption, 0))))": 545.4018808857362,
                    "((CAST((sum((IF(((Segment = LAM) AND Date LIKE 2013%), Consumption, 0))) - sum((IF(((Segment = LAM) AND Date LIKE 2012%), Consumption, 0)))) AS FLOAT) * 100) / sum((IF(((Segment = LAM) AND Date LIKE 2012%), Consumption, 0))))": 681.5824507359694,
                    "((CAST((sum((IF(((Segment = KAM) AND Date LIKE 2013%), Consumption, 0))) - sum((IF(((Segment = KAM) AND Date LIKE 2012%), Consumption, 0)))) AS FLOAT) * 100) / sum((IF(((Segment = KAM) AND Date LIKE 2012%), Consumption, 0))))": 708.1124296835188
                }
            ]
        ],
        "spark_error": [
            "An error occurred while calling o2395.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1235.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1235.0 (TID 1190) (tuxedo-os-2.fritz.box executor driver): java.sql.SQLException: Error parsing date\n\tat org.sqlite.jdbc3.JDBC3ResultSet.getDate(JDBC3ResultSet.java:250)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$makeGetter$2(JdbcUtils.scala:416)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$makeGetter$2$adapted(JdbcUtils.scala:414)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:376)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:357)\n\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\nCaused by: java.text.ParseException: Unparseable date: \"2012-08-24\" does not match (\\p{Nd}++)\\Q-\\E(\\p{Nd}++)\\Q-\\E(\\p{Nd}++)\\Q \\E(\\p{Nd}++)\\Q:\\E(\\p{Nd}++)\\Q:\\E(\\p{Nd}++)\\Q.\\E(\\p{Nd}++)\n\tat org.sqlite.date.FastDateParser.parse(FastDateParser.java:311)\n\tat org.sqlite.date.FastDateFormat.parse(FastDateFormat.java:449)\n\tat org.sqlite.jdbc3.JDBC3ResultSet.getDate(JDBC3ResultSet.java:248)\n\t... 25 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\n\tat scala.collection.immutable.List.foreach(List.scala:334)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\n\tat scala.Option.foreach(Option.scala:437)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\nCaused by: java.sql.SQLException: Error parsing date\n\tat org.sqlite.jdbc3.JDBC3ResultSet.getDate(JDBC3ResultSet.java:250)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$makeGetter$2(JdbcUtils.scala:416)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$makeGetter$2$adapted(JdbcUtils.scala:414)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:376)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:357)\n\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\nCaused by: java.text.ParseException: Unparseable date: \"2012-08-24\" does not match (\\p{Nd}++)\\Q-\\E(\\p{Nd}++)\\Q-\\E(\\p{Nd}++)\\Q \\E(\\p{Nd}++)\\Q:\\E(\\p{Nd}++)\\Q:\\E(\\p{Nd}++)\\Q.\\E(\\p{Nd}++)\n\tat org.sqlite.date.FastDateParser.parse(FastDateParser.java:311)\n\tat org.sqlite.date.FastDateFormat.parse(FastDateFormat.java:449)\n\tat org.sqlite.jdbc3.JDBC3ResultSet.getDate(JDBC3ResultSet.java:248)\n\t... 25 more\n",
            null,
            "An error occurred while calling o1399.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 772.0 failed 1 times, most recent failure: Lost task 0.0 in stage 772.0 (TID 660) (tuxedo-os-2.fritz.box executor driver): java.sql.SQLException: Error parsing date\n\tat org.sqlite.jdbc3.JDBC3ResultSet.getDate(JDBC3ResultSet.java:250)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$makeGetter$2(JdbcUtils.scala:416)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$makeGetter$2$adapted(JdbcUtils.scala:414)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:376)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:357)\n\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\nCaused by: java.text.ParseException: Unparseable date: \"2012-08-24\" does not match (\\p{Nd}++)\\Q-\\E(\\p{Nd}++)\\Q-\\E(\\p{Nd}++)\\Q \\E(\\p{Nd}++)\\Q:\\E(\\p{Nd}++)\\Q:\\E(\\p{Nd}++)\\Q.\\E(\\p{Nd}++)\n\tat org.sqlite.date.FastDateParser.parse(FastDateParser.java:311)\n\tat org.sqlite.date.FastDateFormat.parse(FastDateFormat.java:449)\n\tat org.sqlite.jdbc3.JDBC3ResultSet.getDate(JDBC3ResultSet.java:248)\n\t... 25 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\n\tat scala.collection.immutable.List.foreach(List.scala:334)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\n\tat scala.Option.foreach(Option.scala:437)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\nCaused by: java.sql.SQLException: Error parsing date\n\tat org.sqlite.jdbc3.JDBC3ResultSet.getDate(JDBC3ResultSet.java:250)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$makeGetter$2(JdbcUtils.scala:416)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$makeGetter$2$adapted(JdbcUtils.scala:414)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:376)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:357)\n\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\nCaused by: java.text.ParseException: Unparseable date: \"2012-08-24\" does not match (\\p{Nd}++)\\Q-\\E(\\p{Nd}++)\\Q-\\E(\\p{Nd}++)\\Q \\E(\\p{Nd}++)\\Q:\\E(\\p{Nd}++)\\Q:\\E(\\p{Nd}++)\\Q.\\E(\\p{Nd}++)\n\tat org.sqlite.date.FastDateParser.parse(FastDateParser.java:311)\n\tat org.sqlite.date.FastDateFormat.parse(FastDateFormat.java:449)\n\tat org.sqlite.jdbc3.JDBC3ResultSet.getDate(JDBC3ResultSet.java:248)\n\t... 25 more\n",
            null,
            "An error occurred while calling o2659.collectToPython.\n: org.apache.spark.SparkException: Multiple failures in stage materialization.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.multiFailuresInStageMaterializationError(QueryExecutionErrors.scala:1939)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.cleanUpAndThrowException(AdaptiveSparkPlanExec.scala:900)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$withFinalPlanUpdate$1(AdaptiveSparkPlanExec.scala:347)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:279)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:402)\n\tat org.apache.spark.sql.classic.Dataset.$anonfun$collectToPython$1(Dataset.scala:2057)\n\tat org.apache.spark.sql.classic.Dataset.$anonfun$withAction$2(Dataset.scala:2234)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)\n\tat org.apache.spark.sql.classic.Dataset.$anonfun$withAction$1(Dataset.scala:2232)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$8(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:272)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$7(SQLExecution.scala:125)\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:106)\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:295)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:124)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:237)\n\tat org.apache.spark.sql.classic.Dataset.withAction(Dataset.scala:2232)\n\tat org.apache.spark.sql.classic.Dataset.collectToPython(Dataset.scala:2054)\n\tat jdk.internal.reflect.GeneratedMethodAccessor66.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\n\tSuppressed: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1354.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1354.0 (TID 1327) (tuxedo-os-2.fritz.box executor driver): java.sql.SQLException: Error parsing date\n\tat org.sqlite.jdbc3.JDBC3ResultSet.getDate(JDBC3ResultSet.java:250)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$makeGetter$2(JdbcUtils.scala:416)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$makeGetter$2$adapted(JdbcUtils.scala:414)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:376)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:357)\n\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\nCaused by: java.text.ParseException: Unparseable date: \"2012-08-24\" does not match (\\p{Nd}++)\\Q-\\E(\\p{Nd}++)\\Q-\\E(\\p{Nd}++)\\Q \\E(\\p{Nd}++)\\Q:\\E(\\p{Nd}++)\\Q:\\E(\\p{Nd}++)\\Q.\\E(\\p{Nd}++)\n\tat org.sqlite.date.FastDateParser.parse(FastDateParser.java:311)\n\tat org.sqlite.date.FastDateFormat.parse(FastDateFormat.java:449)\n\tat org.sqlite.jdbc3.JDBC3ResultSet.getDate(JDBC3ResultSet.java:248)\n\t... 25 more\n\nDriver stacktrace:\n\t\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\n\t\tat scala.Option.getOrElse(Option.scala:201)\n\t\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\n\t\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\n\t\tat scala.collection.immutable.List.foreach(List.scala:334)\n\t\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\n\t\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\n\t\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\n\t\tat scala.Option.foreach(Option.scala:437)\n\t\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\n\t\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\n\t\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\n\t\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\n\t\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\n\tCaused by: java.sql.SQLException: Error parsing date\n\t\tat org.sqlite.jdbc3.JDBC3ResultSet.getDate(JDBC3ResultSet.java:250)\n\t\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$makeGetter$2(JdbcUtils.scala:416)\n\t\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$makeGetter$2$adapted(JdbcUtils.scala:414)\n\t\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:376)\n\t\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:357)\n\t\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n\t\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\t\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\t\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.processNext(Unknown Source)\n\t\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\t\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n\t\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\t\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)\n\t\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n\t\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n\t\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\t\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n\t\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n\t\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n\t\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n\t\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n\t\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n\t\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n\t\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n\t\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n\t\tat java.base/java.lang.Thread.run(Thread.java:1583)\n\tCaused by: java.text.ParseException: Unparseable date: \"2012-08-24\" does not match (\\p{Nd}++)\\Q-\\E(\\p{Nd}++)\\Q-\\E(\\p{Nd}++)\\Q \\E(\\p{Nd}++)\\Q:\\E(\\p{Nd}++)\\Q:\\E(\\p{Nd}++)\\Q.\\E(\\p{Nd}++)\n\t\tat org.sqlite.date.FastDateParser.parse(FastDateParser.java:311)\n\t\tat org.sqlite.date.FastDateFormat.parse(FastDateFormat.java:449)\n\t\tat org.sqlite.jdbc3.JDBC3ResultSet.getDate(JDBC3ResultSet.java:248)\n\t\t... 25 more\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1353.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1353.0 (TID 1326) (tuxedo-os-2.fritz.box executor driver): java.sql.SQLException: Error parsing date\n\tat org.sqlite.jdbc3.JDBC3ResultSet.getDate(JDBC3ResultSet.java:250)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$makeGetter$2(JdbcUtils.scala:416)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$makeGetter$2$adapted(JdbcUtils.scala:414)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:376)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:357)\n\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\nCaused by: java.text.ParseException: Unparseable date: \"2012-08-24\" does not match (\\p{Nd}++)\\Q-\\E(\\p{Nd}++)\\Q-\\E(\\p{Nd}++)\\Q \\E(\\p{Nd}++)\\Q:\\E(\\p{Nd}++)\\Q:\\E(\\p{Nd}++)\\Q.\\E(\\p{Nd}++)\n\tat org.sqlite.date.FastDateParser.parse(FastDateParser.java:311)\n\tat org.sqlite.date.FastDateFormat.parse(FastDateFormat.java:449)\n\tat org.sqlite.jdbc3.JDBC3ResultSet.getDate(JDBC3ResultSet.java:248)\n\t... 25 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\n\tat scala.collection.immutable.List.foreach(List.scala:334)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\n\tat scala.Option.foreach(Option.scala:437)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\nCaused by: java.sql.SQLException: Error parsing date\n\tat org.sqlite.jdbc3.JDBC3ResultSet.getDate(JDBC3ResultSet.java:250)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$makeGetter$2(JdbcUtils.scala:416)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$makeGetter$2$adapted(JdbcUtils.scala:414)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:376)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:357)\n\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\nCaused by: java.text.ParseException: Unparseable date: \"2012-08-24\" does not match (\\p{Nd}++)\\Q-\\E(\\p{Nd}++)\\Q-\\E(\\p{Nd}++)\\Q \\E(\\p{Nd}++)\\Q:\\E(\\p{Nd}++)\\Q:\\E(\\p{Nd}++)\\Q.\\E(\\p{Nd}++)\n\tat org.sqlite.date.FastDateParser.parse(FastDateParser.java:311)\n\tat org.sqlite.date.FastDateFormat.parse(FastDateFormat.java:449)\n\tat org.sqlite.jdbc3.JDBC3ResultSet.getDate(JDBC3ResultSet.java:248)\n\t... 25 more\n",
            "An error occurred while calling o1459.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 777.0 failed 1 times, most recent failure: Lost task 0.0 in stage 777.0 (TID 672) (tuxedo-os-2.fritz.box executor driver): java.sql.SQLException: Error parsing date\n\tat org.sqlite.jdbc3.JDBC3ResultSet.getDate(JDBC3ResultSet.java:250)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$makeGetter$2(JdbcUtils.scala:416)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$makeGetter$2$adapted(JdbcUtils.scala:414)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:376)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:357)\n\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\nCaused by: java.text.ParseException: Unparseable date: \"2012-08-24\" does not match (\\p{Nd}++)\\Q-\\E(\\p{Nd}++)\\Q-\\E(\\p{Nd}++)\\Q \\E(\\p{Nd}++)\\Q:\\E(\\p{Nd}++)\\Q:\\E(\\p{Nd}++)\\Q.\\E(\\p{Nd}++)\n\tat org.sqlite.date.FastDateParser.parse(FastDateParser.java:311)\n\tat org.sqlite.date.FastDateFormat.parse(FastDateFormat.java:449)\n\tat org.sqlite.jdbc3.JDBC3ResultSet.getDate(JDBC3ResultSet.java:248)\n\t... 25 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\n\tat scala.collection.immutable.List.foreach(List.scala:334)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\n\tat scala.Option.foreach(Option.scala:437)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\nCaused by: java.sql.SQLException: Error parsing date\n\tat org.sqlite.jdbc3.JDBC3ResultSet.getDate(JDBC3ResultSet.java:250)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$makeGetter$2(JdbcUtils.scala:416)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$makeGetter$2$adapted(JdbcUtils.scala:414)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:376)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:357)\n\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\nCaused by: java.text.ParseException: Unparseable date: \"2012-08-24\" does not match (\\p{Nd}++)\\Q-\\E(\\p{Nd}++)\\Q-\\E(\\p{Nd}++)\\Q \\E(\\p{Nd}++)\\Q:\\E(\\p{Nd}++)\\Q:\\E(\\p{Nd}++)\\Q.\\E(\\p{Nd}++)\n\tat org.sqlite.date.FastDateParser.parse(FastDateParser.java:311)\n\tat org.sqlite.date.FastDateFormat.parse(FastDateFormat.java:449)\n\tat org.sqlite.jdbc3.JDBC3ResultSet.getDate(JDBC3ResultSet.java:248)\n\t... 25 more\n",
            null,
            null,
            "An error occurred while calling o1927.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1006.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1006.0 (TID 931) (tuxedo-os-2.fritz.box executor driver): java.sql.SQLException: Error parsing date\n\tat org.sqlite.jdbc3.JDBC3ResultSet.getDate(JDBC3ResultSet.java:250)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$makeGetter$2(JdbcUtils.scala:416)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$makeGetter$2$adapted(JdbcUtils.scala:414)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:376)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:357)\n\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\nCaused by: java.text.ParseException: Unparseable date: \"2012-08-24\" does not match (\\p{Nd}++)\\Q-\\E(\\p{Nd}++)\\Q-\\E(\\p{Nd}++)\\Q \\E(\\p{Nd}++)\\Q:\\E(\\p{Nd}++)\\Q:\\E(\\p{Nd}++)\\Q.\\E(\\p{Nd}++)\n\tat org.sqlite.date.FastDateParser.parse(FastDateParser.java:311)\n\tat org.sqlite.date.FastDateFormat.parse(FastDateFormat.java:449)\n\tat org.sqlite.jdbc3.JDBC3ResultSet.getDate(JDBC3ResultSet.java:248)\n\t... 25 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\n\tat scala.collection.immutable.List.foreach(List.scala:334)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1295)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1295)\n\tat scala.Option.foreach(Option.scala:437)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1295)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3207)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\nCaused by: java.sql.SQLException: Error parsing date\n\tat org.sqlite.jdbc3.JDBC3ResultSet.getDate(JDBC3ResultSet.java:250)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$makeGetter$2(JdbcUtils.scala:416)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$makeGetter$2$adapted(JdbcUtils.scala:414)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:376)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:357)\n\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:143)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:57)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:111)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\nCaused by: java.text.ParseException: Unparseable date: \"2012-08-24\" does not match (\\p{Nd}++)\\Q-\\E(\\p{Nd}++)\\Q-\\E(\\p{Nd}++)\\Q \\E(\\p{Nd}++)\\Q:\\E(\\p{Nd}++)\\Q:\\E(\\p{Nd}++)\\Q.\\E(\\p{Nd}++)\n\tat org.sqlite.date.FastDateParser.parse(FastDateParser.java:311)\n\tat org.sqlite.date.FastDateFormat.parse(FastDateFormat.java:449)\n\tat org.sqlite.jdbc3.JDBC3ResultSet.getDate(JDBC3ResultSet.java:248)\n\t... 25 more\n",
            null
        ],
        "total_time": [
            30.477462768554688,
            23.70546054840088,
            13.583703756332397,
            12.825434684753418,
            26.67790412902832,
            13.138661623001099,
            49.846699476242065,
            34.54461908340454,
            12.40068244934082,
            24.005382537841797
        ],
        "spark_time": [
            0.38163018226623535,
            0.417651891708374,
            0.369020938873291,
            0.6745541095733643,
            0.28734827041625977,
            0.07438540458679199,
            0.443448543548584,
            1.138801097869873,
            0.05428028106689453,
            0.4862785339355469
        ],
        "translation_time": [
            30.095832586288452,
            23.287808656692505,
            13.214682817459106,
            12.150880575180054,
            26.39055585861206,
            13.064276218414307,
            49.40325093269348,
            33.40581798553467,
            12.346402168273926,
            23.51910400390625
        ],
        "jaccard_index": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        "jaccard_index_new": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ],
        "exact_match": [
            0,
            0,
            0,
            0,
            0
        ],
        "total_time_avg": 24.120601105690003,
        "spark_time_avg": 0.4327399253845215,
        "translation_time_avg": 23.687861180305482,
        "jaccard_index_avg": 0.0,
        "jaccard_index_new_avg": 0.0,
        "exact_match_avg": 0.0
    }
}