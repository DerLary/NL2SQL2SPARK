{
    "query_id": 134,
    "difficulty": "simple",
    "is_initial": true,
    "nl_query": "In the branch where the largest number of crimes were committed in 1996, how many accounts were opened? A16 stands for no. of committed crimes 1996",
    "golden_query": "SELECT COUNT(T2.account_id) FROM district AS T1 INNER JOIN account AS T2 ON T1.district_id = T2.district_id GROUP BY T1.A16 ORDER BY T1.A16 DESC LIMIT 1",
    "sparksql_query": "SELECT COUNT(`account_id`) FROM `account` WHERE `district_id` = (SELECT `district_id` FROM `district` ORDER BY `A16` DESC LIMIT 1)",
    "jaccard_index": 1.0,
    "exact_match": 0,
    "ground_truth": [
        {
            "count(account_id)": 554
        }
    ],
    "query_result": [
        [
            "554"
        ]
    ],
    "execution_plans": {
        "golden_query": "\nExecution Plan for: Golden Query ID 134...\n================================================================================\n\n1. Logical plan:\n----------------------------------------\n'GlobalLimit 1\n+- 'LocalLimit 1\n   +- 'Sort ['T1.A16 DESC NULLS LAST], true\n      +- 'Aggregate ['T1.A16], [unresolvedalias('COUNT('T2.account_id))]\n         +- 'Join Inner, ('T1.district_id = 'T2.district_id)\n            :- 'SubqueryAlias T1\n            :  +- 'UnresolvedRelation [district], [], false\n            +- 'SubqueryAlias T2\n               +- 'UnresolvedRelation [account], [], false\n\n\n2. Optimized logical plan (After Catalyst AFAIK):\n----------------------------------------\nGlobalLimit 1\n+- LocalLimit 1\n   +- Project [count(account_id)#4564L]\n      +- Sort [A16#4539 DESC NULLS LAST], true\n         +- Aggregate [A16#4539], [count(account_id#4508) AS count(account_id)#4564L, A16#4539]\n            +- Project [A16#4539, account_id#4508]\n               +- Join Inner, (district_id#4524 = district_id#4509)\n                  :- Project [district_id#4524, A16#4539]\n                  :  +- Filter isnotnull(district_id#4524)\n                  :     +- Relation [district_id#4524,A2#4525,A3#4526,A4#4527,A5#4528,A6#4529,A7#4530,A8#4531,A9#4532,A10#4533,A11#4534,A12#4535,A13#4536,A14#4537,A15#4538,A16#4539] JDBCRelation((SELECT \"district_id\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\", \"A8\", \"A9\", \"A10\", \"A11\", \"A12\", \"A13\", \"A14\", \"A15\", \"A16\" FROM \"district\") AS \"district\") [numPartitions=1]\n                  +- Project [account_id#4508, district_id#4509]\n                     +- Filter isnotnull(district_id#4509)\n                        +- Relation [account_id#4508,district_id#4509,frequency#4510,date#4511] JDBCRelation((SELECT \"account_id\", \"district_id\", \"frequency\", CAST(\"date\" AS TEXT) AS \"date\" FROM \"account\") AS \"account\") [numPartitions=1]\n\n\n3. Physical plan:\n----------------------------------------\nAdaptiveSparkPlan isFinalPlan=false\n+- TakeOrderedAndProject(limit=1, orderBy=[A16#4539 DESC NULLS LAST], output=[count(account_id)#4564L])\n  +- HashAggregate(keys=[A16#4539], functions=[count(account_id#4508)], output=[count(account_id)#4564L, A16#4539])\n      +- Exchange hashpartitioning(A16#4539, 200), ENSURE_REQUIREMENTS, [plan_id=9361]\n        +- HashAggregate(keys=[A16#4539], functions=[partial_count(account_id#4508)], output=[A16#4539, count#4566L])\n            +- Project [A16#4539, account_id#4508]\n              +- SortMergeJoin [district_id#4524], [district_id#4509], Inner\n                  :- Sort [district_id#4524 ASC NULLS FIRST], false, 0\n                  :  +- Exchange hashpartitioning(district_id#4524, 200), ENSURE_REQUIREMENTS, [plan_id=9353]\n                  :     +- Scan JDBCRelation((SELECT \"district_id\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\", \"A8\", \"A9\", \"A10\", \"A11\", \"A12\", \"A13\", \"A14\", \"A15\", \"A16\" FROM \"district\") AS \"district\") [numPartitions=1] [district_id#4524,A16#4539] PushedFilters: [*IsNotNull(district_id)], ReadSchema: struct<district_id:int,A16:int>\n                  +- Sort [district_id#4509 ASC NULLS FIRST], false, 0\n                    +- Exchange hashpartitioning(district_id#4509, 200), ENSURE_REQUIREMENTS, [plan_id=9354]\n                        +- Scan JDBCRelation((SELECT \"account_id\", \"district_id\", \"frequency\", CAST(\"date\" AS TEXT) AS \"date\" FROM \"account\") AS \"account\") [numPartitions=1] [account_id#4508,district_id#4509] PushedFilters: [*IsNotNull(district_id)], ReadSchema: struct<account_id:int,district_id:int>\n\n4. Explain output:\n----------------------------------------\n\nPhysical Plan ==:\n-----------------\n  AdaptiveSparkPlan isFinalPlan=false\n  +- TakeOrderedAndProject(limit=1, orderBy=[A16#4539 DESC NULLS LAST], output=[count(account_id)#4572L])\n  +- HashAggregate(keys=[A16#4539], functions=[count(account_id#4508)])\n  +- Exchange hashpartitioning(A16#4539, 200), ENSURE_REQUIREMENTS, [plan_id=9402]\n  +- HashAggregate(keys=[A16#4539], functions=[partial_count(account_id#4508)])\n  +- Project [A16#4539, account_id#4508]\n  +- SortMergeJoin [district_id#4524], [district_id#4509], Inner\n  :- Sort [district_id#4524 ASC NULLS FIRST], false, 0\n  :  +- Exchange hashpartitioning(district_id#4524, 200), ENSURE_REQUIREMENTS, [plan_id=9394]\n  :     +- Scan JDBCRelation((SELECT \"district_id\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\", \"A8\", \"A9\", \"A10\", \"A11\", \"A12\", \"A13\", \"A14\", \"A15\", \"A16\" FROM \"district\") AS \"district\") [numPartitions=1] [district_id#4524,A16#4539] PushedFilters: [*IsNotNull(district_id)], ReadSchema: struct<district_id:int,A16:int>\n  +- Sort [district_id#4509 ASC NULLS FIRST], false, 0\n  +- Exchange hashpartitioning(district_id#4509, 200), ENSURE_REQUIREMENTS, [plan_id=9395]\n  +- Scan JDBCRelation((SELECT \"account_id\", \"district_id\", \"frequency\", CAST(\"date\" AS TEXT) AS \"date\" FROM \"account\") AS \"account\") [numPartitions=1] [account_id#4508,district_id#4509] PushedFilters: [*IsNotNull(district_id)], ReadSchema: struct<account_id:int,district_id:int>\n================================================================================",
        "model_query": "\nExecution Plan for: Model Query ID 134...\n================================================================================\n\n1. Logical plan:\n----------------------------------------\n'Project [unresolvedalias('COUNT('account_id))]\n+- 'Filter ('district_id = scalar-subquery#4575 [])\n   :  +- 'GlobalLimit 1\n   :     +- 'LocalLimit 1\n   :        +- 'Sort ['A16 DESC NULLS LAST], true\n   :           +- 'Project ['district_id]\n   :              +- 'UnresolvedRelation [district], [], false\n   +- 'UnresolvedRelation [account], [], false\n\n\n2. Optimized logical plan (After Catalyst AFAIK):\n----------------------------------------\nAggregate [count(account_id#4508) AS count(account_id)#4577L]\n+- Project [account_id#4508]\n   +- Filter (isnotnull(district_id#4509) AND (district_id#4509 = scalar-subquery#4575 []))\n      :  +- GlobalLimit 1\n      :     +- LocalLimit 1\n      :        +- Project [district_id#4524]\n      :           +- Sort [A16#4539 DESC NULLS LAST], true\n      :              +- Project [district_id#4524, A16#4539]\n      :                 +- Relation [district_id#4524,A2#4525,A3#4526,A4#4527,A5#4528,A6#4529,A7#4530,A8#4531,A9#4532,A10#4533,A11#4534,A12#4535,A13#4536,A14#4537,A15#4538,A16#4539] JDBCRelation((SELECT \"district_id\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\", \"A8\", \"A9\", \"A10\", \"A11\", \"A12\", \"A13\", \"A14\", \"A15\", \"A16\" FROM \"district\") AS \"district\") [numPartitions=1]\n      +- Relation [account_id#4508,district_id#4509,frequency#4510,date#4511] JDBCRelation((SELECT \"account_id\", \"district_id\", \"frequency\", CAST(\"date\" AS TEXT) AS \"date\" FROM \"account\") AS \"account\") [numPartitions=1]\n\n\n3. Physical plan:\n----------------------------------------\nAdaptiveSparkPlan isFinalPlan=false\n+- HashAggregate(keys=[], functions=[count(account_id#4508)], output=[count(account_id)#4577L])\n  +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=9433]\n      +- HashAggregate(keys=[], functions=[partial_count(account_id#4508)], output=[count#4579L])\n        +- Project [account_id#4508]\n            +- Filter (district_id#4509 = Subquery subquery#4575, [id=#9427])\n              :  +- Subquery subquery#4575, [id=#9427]\n              :     +- AdaptiveSparkPlan isFinalPlan=false\n              :        +- TakeOrderedAndProject(limit=1, orderBy=[A16#4539 DESC NULLS LAST], output=[district_id#4524])\n              :           +- Scan JDBCRelation((SELECT \"district_id\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\", \"A8\", \"A9\", \"A10\", \"A11\", \"A12\", \"A13\", \"A14\", \"A15\", \"A16\" FROM \"district\") AS \"district\") [numPartitions=1] [district_id#4524,A16#4539] PushedFilters: [], ReadSchema: struct<district_id:int,A16:int>\n              +- Scan JDBCRelation((SELECT \"account_id\", \"district_id\", \"frequency\", CAST(\"date\" AS TEXT) AS \"date\" FROM \"account\") AS \"account\") [numPartitions=1] [account_id#4508,district_id#4509] PushedFilters: [*IsNotNull(district_id)], ReadSchema: struct<account_id:int,district_id:int>\n\n4. Explain output:\n----------------------------------------\n\nPhysical Plan ==:\n-----------------\n  AdaptiveSparkPlan isFinalPlan=false\n  +- HashAggregate(keys=[], functions=[count(account_id#4508)])\n  +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=9463]\n  +- HashAggregate(keys=[], functions=[partial_count(account_id#4508)])\n  +- Project [account_id#4508]\n  +- Filter (district_id#4509 = Subquery subquery#4580, [id=#9457])\n  :  +- Subquery subquery#4580, [id=#9457]\n  :     +- AdaptiveSparkPlan isFinalPlan=false\n  :        +- TakeOrderedAndProject(limit=1, orderBy=[A16#4539 DESC NULLS LAST], output=[district_id#4524])\n  :           +- Scan JDBCRelation((SELECT \"district_id\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\", \"A8\", \"A9\", \"A10\", \"A11\", \"A12\", \"A13\", \"A14\", \"A15\", \"A16\" FROM \"district\") AS \"district\") [numPartitions=1] [district_id#4524,A16#4539] PushedFilters: [], ReadSchema: struct<district_id:int,A16:int>\n  +- Scan JDBCRelation((SELECT \"account_id\", \"district_id\", \"frequency\", CAST(\"date\" AS TEXT) AS \"date\" FROM \"account\") AS \"account\") [numPartitions=1] [account_id#4508,district_id#4509] PushedFilters: [*IsNotNull(district_id)], ReadSchema: struct<account_id:int,district_id:int>\n================================================================================"
    },
    "result_file_path": "/home/lars/Privat/RWTH/Auslandssemester/#KURSE/Safe Distributed Systems/Exercises/Practical_Exercise/NL2SQL2SPARK/RAW_RESULTS/benchmark_results_20251231_google_06264356/134/20251231_125114_ID_134_ITER_7_a1d11e31.json",
    "explainer_metrics": {
        "golden_query": {
            "shuffle_count": {
                "Exchange\\s+hashpartitioning\\(": 3,
                "Exchange\\s+rangepartitioning\\(": 0,
                "Exchange\\s+SinglePartition": 0,
                "ShuffleExchange": 0,
                "TOTAL": 3
            },
            "has_broadcast_join": false,
            "has_predicate_pushdown": true,
            "pushed_filters": [
                {
                    "scan_line": ":     +- Scan JDBCRelation((SELECT \"district_id\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\", \"A8\", \"A9\", \"A10\", \"A11\", \"A12\", \"A13\", \"A14\", \"A15\", \"A16\" FROM \"district\") AS \"district\") [numPartitions=1] [district_id#4524,A16#4539] PushedFilters: [*IsNotNull(district_id)], ReadSchema: struct<district_id:int,A16:int>",
                    "filters": [
                        "*IsNotNull(district_id)"
                    ]
                },
                {
                    "scan_line": "+- Scan JDBCRelation((SELECT \"account_id\", \"district_id\", \"frequency\", CAST(\"date\" AS TEXT) AS \"date\" FROM \"account\") AS \"account\") [numPartitions=1] [account_id#4508,district_id#4509] PushedFilters: [*IsNotNull(district_id)], ReadSchema: struct<account_id:int,district_id:int>",
                    "filters": [
                        "*IsNotNull(district_id)"
                    ]
                },
                {
                    "scan_line": ":     +- Scan JDBCRelation((SELECT \"district_id\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\", \"A8\", \"A9\", \"A10\", \"A11\", \"A12\", \"A13\", \"A14\", \"A15\", \"A16\" FROM \"district\") AS \"district\") [numPartitions=1] [district_id#4524,A16#4539] PushedFilters: [*IsNotNull(district_id)], ReadSchema: struct<district_id:int,A16:int>",
                    "filters": [
                        "*IsNotNull(district_id)"
                    ]
                },
                {
                    "scan_line": "+- Scan JDBCRelation((SELECT \"account_id\", \"district_id\", \"frequency\", CAST(\"date\" AS TEXT) AS \"date\" FROM \"account\") AS \"account\") [numPartitions=1] [account_id#4508,district_id#4509] PushedFilters: [*IsNotNull(district_id)], ReadSchema: struct<account_id:int,district_id:int>",
                    "filters": [
                        "*IsNotNull(district_id)"
                    ]
                }
            ],
            "filter_count_before_optimization": 0,
            "filter_count_after_optimization": 2
        },
        "model_query": {
            "shuffle_count": {
                "Exchange\\s+hashpartitioning\\(": 0,
                "Exchange\\s+rangepartitioning\\(": 0,
                "Exchange\\s+SinglePartition": 1,
                "ShuffleExchange": 0,
                "TOTAL": 1
            },
            "has_broadcast_join": false,
            "has_predicate_pushdown": true,
            "pushed_filters": [
                {
                    "scan_line": ":           +- Scan JDBCRelation((SELECT \"district_id\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\", \"A8\", \"A9\", \"A10\", \"A11\", \"A12\", \"A13\", \"A14\", \"A15\", \"A16\" FROM \"district\") AS \"district\") [numPartitions=1] [district_id#4524,A16#4539] PushedFilters: [], ReadSchema: struct<district_id:int,A16:int>",
                    "filters": []
                },
                {
                    "scan_line": "+- Scan JDBCRelation((SELECT \"account_id\", \"district_id\", \"frequency\", CAST(\"date\" AS TEXT) AS \"date\" FROM \"account\") AS \"account\") [numPartitions=1] [account_id#4508,district_id#4509] PushedFilters: [*IsNotNull(district_id)], ReadSchema: struct<account_id:int,district_id:int>",
                    "filters": [
                        "*IsNotNull(district_id)"
                    ]
                },
                {
                    "scan_line": ":           +- Scan JDBCRelation((SELECT \"district_id\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\", \"A8\", \"A9\", \"A10\", \"A11\", \"A12\", \"A13\", \"A14\", \"A15\", \"A16\" FROM \"district\") AS \"district\") [numPartitions=1] [district_id#4524,A16#4539] PushedFilters: [], ReadSchema: struct<district_id:int,A16:int>",
                    "filters": []
                },
                {
                    "scan_line": "+- Scan JDBCRelation((SELECT \"account_id\", \"district_id\", \"frequency\", CAST(\"date\" AS TEXT) AS \"date\" FROM \"account\") AS \"account\") [numPartitions=1] [account_id#4508,district_id#4509] PushedFilters: [*IsNotNull(district_id)], ReadSchema: struct<account_id:int,district_id:int>",
                    "filters": [
                        "*IsNotNull(district_id)"
                    ]
                }
            ],
            "filter_count_before_optimization": 0,
            "filter_count_after_optimization": 1
        },
        "plan_equivalence": {
            "golden_vs_model_physical_equivalent": false
        }
    }
}